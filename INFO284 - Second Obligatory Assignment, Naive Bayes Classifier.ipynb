{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate two sets of parameters from the training set to build your classifier\n",
    "Use naive Bayes to create the classifer, in order to predict whether a news text is \"fake news\" or not.\n",
    "\tAre the words in a text sufficient for a successful classification?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set of parameters to estimate:\n",
    "\tThe prior probabilities of the class P(y = yk)\n",
    "\t\tFor each class yk element {0,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second set of parameters to estimate:\n",
    "\tLikelihood probabilities P(w = wi|y = yk)\n",
    "\t\tfor each word wi in the vocabulary V\n",
    "\t\t\twhere vocabulary V consists of a set of unique words from all news articals in the training set\n",
    "\t\t\tand which you constructed in the first obligatory assignment.\n",
    "\t\tLikelihood probability of word wi given class yk is the number of times wi occurs in a news article with label yk\n",
    "\t\t\tfrom total number of news articles in trainig set labeled with yk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once classifier is built, do:\n",
    "\tTry out classifier on test set\n",
    "\tCalculate error rate\n",
    "\t\tError rate is number of articles from test set incorrectly labeled, divided by total nubmer of articles in the test set\n",
    "\tCreate an evaluation function that can be used on the command line to evaluate a short news artivle that you can copy-paste yourself\n",
    "\tWhen a news article contains a word not in V (vocabulary)\n",
    "\t\tthen posterior class probabilities are zero\n",
    "\t\tovercome problem you can use smoothing technique\n",
    "\t\t\tLaplace smoothing, calcyualte likelihood probabilties as\n",
    "\t\t\t\tformulae\n",
    "\t\t\t\t\twhere the #R{} denoted the number of elements in the training set of news articles R that satisfy the constraint in the brackets, and |V| is the cardinality of the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit, in one compressed folder:\n",
    "\tpython code\n",
    "\t\tcarefulle annotated to be understood by non-author\n",
    "\t\tInstructions on how to run the code and how to test a news article from the command line.\n",
    "\t\tA short text (max 1 page) on your analysis of the classifier you have created:\n",
    "\t\t\tAre there words, combinations of words, meta data that with high probaiblity point to a news article being \"fake news\"?\n",
    "\t\t\tIs naive Bayes a good method for solving the problem of classifying \"fake news\"? \tWhy/why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of reliable/unreliable divided by total number of articles in training set\n",
    "\n",
    "Second set of parameters to estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Number of reliable texts divided by total number of articles\n",
    "#Number of unreliable texts divided by total number of articles\n",
    "\n",
    "#Import the data sets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
